{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_auc_score, f1_score\n","from sklearn.utils.class_weight import compute_class_weight\n","from lightgbm import LGBMClassifier\n","import pandas as pd\n","import numpy as np\n","import optuna\n","from utils import run_study\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CONFIG\n","\n","kfolds = RepeatedStratifiedKFold(n_splits=5, n_repeats=3)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","df = pd.read_csv('data/data_preprocessed/qscore.csv')\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# WITH MISSING DATA\n","\n","train = df[df[\"year\"] != \"2018/19\"].drop([\"year\"], axis=1)\n","X_train = train.drop([\"hip_replacement_post_op_q_score_bin\"], axis=1)\n","y_train = train[\"hip_replacement_post_op_q_score_bin\"]\n","\n","test = df[df[\"year\"] == \"2018/19\"].drop([\"year\"], axis=1)\n","X_test = test.drop([\"hip_replacement_post_op_q_score_bin\"], axis=1)\n","y_test = test[\"hip_replacement_post_op_q_score_bin\"]\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# WITHOUT MISSING\n","train_nm = train.dropna()\n","X_train_nm = train_nm.drop([\"hip_replacement_post_op_q_score_bin\"], axis=1)\n","y_train_nm = train_nm[\"hip_replacement_post_op_q_score_bin\"]\n","\n","test_nm = test.dropna()\n","X_test_nm = test_nm.drop([\"hip_replacement_post_op_q_score_bin\"], axis=1)\n","y_test_nm = test_nm[\"hip_replacement_post_op_q_score_bin\"]\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# skal have kørt pipelines ind i obj_func\n","# den smider nogle fejl\n","# har ikke weightet, one_hottet eller noget andet ...\n","\n","# jeg kan lave split ds funktion så jeg splitter inde i objektive .. kan teste om missing med impute eller ej virker\n","\n","\n","def obj_logr(trial):\n","    logreg = LogisticRegression(\n","        solver=\"saga\",\n","        l1_ratio=trial.suggest_float(\"l1_ratio\", 0, 1),\n","        C=trial.suggest_loguniform(\"C\", 1e-6, 1))\n","\n","    cv_score = cross_val_score(logreg, X_train_nm, y_train_nm,\n","                               scoring=\"roc_auc\", cv=kfolds, n_jobs=-1)\n","    return np.mean(cv_score)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","study_logr = run_study(obj_logr, n_trials=10, study_name=\"logr\")\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","logr = logreg = LogisticRegression(\n","    solver=\"saga\",\n","    l1_ratio=0.83,\n","    C=0.05)\n","\n","logr.fit(X_train_nm, y_train_nm)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["probas = logr.predict_proba(X_test_nm)\n","roc_auc_score(y_test_nm, probas[:, 1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# SKAL ÆNDRE NAMES TIL AT VÆRE SAMME SOM ARG SÅ JEG KAN BRUGE DICT FRA STUDY\n","\n","\n","def obj_lgbm(trial):\n","    lgbm = LGBMClassifier(\n","        learning_rate=0.1,\n","        max_depth=trial.suggest_int('max_depth', 1, 15),  # usually 3-12 -> tune!\n","        num_iteration=trial.suggest_int(\"num_iter\", 1, 2000),  # 1 - inf -> tune\n","        # tune typical 255 (can be > 4000) -> tune!\n","        num_leaves=trial.suggest_int(\"num_leaves\", 1, 2000),\n","        min_data_in_leaf=trial.suggest_int(\"data_in_leaf\", 1, 50),  # 1- 50 -> Tune!\n","        # prop of rows to sample # typical 0.7 (reducing may improve generalize better?)\n","        sub_row=trial.suggest_int(\"sub_row\", 70, 100) / 100,\n","        # same as sub_row but for cols\n","        sub_feature=trial.suggest_int(\"sub_cols\", 70, 100) / 100,\n","        use_missing=True,\n","        is_unbalanced=True\n","    )\n","    cv_score = cross_val_score(lgbm, X_train, y_train,\n","                               scoring=\"roc_auc\", cv=kfolds, n_jobs=-1)\n","    return np.mean(cv_score)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_lgbm = study.best_params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lgbm = LGBMClassifier(\n","    learning_rate=0.1,\n","    max_depth=14,\n","    num_iteration=388,\n","    num_leaves=1559,\n","    min_data_in_leaf=33,\n","    sub_row=0.99,\n","    sub_feature=0.93,\n","    use_missing=True,\n","    is_unbalanced=True\n",")\n","\n","#lgbm.fit(X_train, y_train)\n","repeat_kfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3)\n","cv_score = cross_val_score(lgbm, X_train, y_train,\n","                           scoring=\"roc_auc\", cv=repeat_kfold, n_jobs=-1)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["probas = lgbm.predict_proba(X_test)\n","roc_auc_score(y_test, probas[:, 1]),\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["preds = lgbm.predict(X_test)\n","f1_score(y_test, preds)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}